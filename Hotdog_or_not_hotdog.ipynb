{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hotdog or not hotdog.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LXgu9c8Zaq0"
      },
      "source": [
        "**Hotdog or not hotdog**\r\n",
        "\r\n",
        "The program imports a dataset named [\"Hot Dog - Not Hot Dog\"](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/notebooks) from Kagggle and then creates and trains a Deep Neural Network to classify the images either in hotdog or not hotdog category. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2upek3PbBqK"
      },
      "source": [
        "**STEP 1:** Importing dataset from Kaggle\r\n",
        "\r\n",
        "**DO NOT RUN AGAIN**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nqzh8AwUQcp"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J-v02TOWV51"
      },
      "source": [
        "import os\r\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\r\n",
        "\r\n",
        "#changing the working directory\r\n",
        "%cd /content/gdrive/My Drive/Kaggle\r\n",
        "\r\n",
        "#checking if in correct directory\r\n",
        "!pwd\r\n",
        "\r\n",
        "#downloading dataset from Kaggle\r\n",
        "!kaggle datasets download -d dansbecker/hot-dog-not-hot-dog\r\n",
        "\r\n",
        "#Verifying the files were downloaded\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPH-cs0AW0Vc"
      },
      "source": [
        "#unzipping and removing zip file\r\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diqQrJtbbVKX"
      },
      "source": [
        "**Step 2:** Normalizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "powWsiC7ZEK0"
      },
      "source": [
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy import ndarray\r\n",
        "from os.path import join\r\n",
        "import glob\r\n",
        "import numpy as np"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vhROHnSgnw3"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle/train/hot_dog/\r\n",
        "file=glob.glob(\"*.jpg\")\r\n",
        "size=64,64\r\n",
        "num_of_files=0\r\n",
        "#resizing images\r\n",
        "for img in file:\r\n",
        "  current_img= Image.open(img)\r\n",
        "  new_img=current_img.resize(size)\r\n",
        "  new_img.save(str(img))\r\n",
        "  num_of_files+=1\r\n",
        "\r\n",
        "%cd /content/gdrive/My Drive/Kaggle/train/not_hot_dog/\r\n",
        "file=glob.glob(\"*.jpg\")\r\n",
        "for img in file:\r\n",
        "  num_of_files+=1\r\n",
        "\r\n",
        "X_train=np.empty((num_of_files,64,64,3))\r\n",
        "Y_train=np.empty((1,num_of_files))\r\n",
        "\r\n",
        "%cd /content/gdrive/My Drive/Kaggle/train/hot_dog/\r\n",
        "file=glob.glob(\"*.jpg\")\r\n",
        "\r\n",
        "#creating an array of images\r\n",
        "i=0\r\n",
        "for img in file:\r\n",
        "  data=np.asarray(Image.open(img))\r\n",
        "  X_train[i]=data\r\n",
        "  Y_train[0][i]=1\r\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HcAQHfDhN7P"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle/train/not_hot_dog/\r\n",
        "file=glob.glob(\"*.jpg\")\r\n",
        "\r\n",
        "#resizing images\r\n",
        "for img in file:\r\n",
        "  current_img= Image.open(img)\r\n",
        "  new_img=current_img.resize(size)\r\n",
        "  new_img.save(str(img))\r\n",
        "\r\n",
        "#creating an array of images\r\n",
        "i=num_of_files//2\r\n",
        "for img in file:\r\n",
        "  data=np.asarray(Image.open(img))\r\n",
        "  X_train[i]=data\r\n",
        "  Y_train[0][i]=0\r\n",
        "  i+=1\r\n",
        "\r\n",
        "X_train=X_train.reshape(X_train.shape[0],-1).T\r\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvuKZTvIg2pN"
      },
      "source": [
        "#standardize the data\r\n",
        "X_train=X_train/255\r\n",
        "print(X_train.shape)\r\n",
        "print(Y_train.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEf-0Y6SwWm0"
      },
      "source": [
        "**Step 2:** Setting up Neural Network\r\n",
        "\r\n",
        "Contains all the function needed for forward and backward propagation for the neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAAU4ES42tBN"
      },
      "source": [
        "Defining activation functions that will be needed for the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ZQyPFOwL3q"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def sigmoid(Z):    \r\n",
        "    A = 1/(1+np.exp(-Z))\r\n",
        "    \r\n",
        "    return A\r\n",
        "\r\n",
        "def relu(Z):\r\n",
        "\r\n",
        "    A = np.maximum(0,Z)\r\n",
        "    \r\n",
        "    assert(A.shape == Z.shape)\r\n",
        "    return A\r\n",
        "\r\n",
        "\r\n",
        "def derivative_relu(dA, cache):\r\n",
        "    Z = cache\r\n",
        "    dZ = np.array(dA, copy=True)\r\n",
        "    dZ[Z <= 0] = 0\r\n",
        "    return dZ\r\n",
        "\r\n",
        "def derivative_sigmoid(dA, cache):\r\n",
        "    Z = cache    \r\n",
        "    dZ = dA * sigmoid(Z) * (1-sigmoid(Z))\r\n",
        "    \r\n",
        "    return dZ"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE6Q97OH7d0L"
      },
      "source": [
        "Initializing parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xzi54Ew7hhl"
      },
      "source": [
        "def initialize_params(layers):\r\n",
        "\r\n",
        "  parameters={}\r\n",
        "\r\n",
        "  for l in range(1,len(layers)):\r\n",
        "    parameters[\"W\"+str(l)]=np.random.randn(layers[l],layers[l-1])*0.01\r\n",
        "    parameters[\"b\"+str(l)]=np.zeros((layers[l],1))\r\n",
        "    print(parameters[\"W\"+str(l)])\r\n",
        "  return parameters "
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRf17h0tyLC_"
      },
      "source": [
        "Forward Propagation: The neural network will consist of a series layers with ReLU as activation function followed by a sigmoid function as the activation function for the last layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OApzvrl31PQS"
      },
      "source": [
        "def linear_forward(W,A,b):\r\n",
        "\r\n",
        "  Z=np.dot(W,A)+b\r\n",
        "\r\n",
        "  assert(Z.shape==(W.shape[0],A.shape[1]))\r\n",
        "  cache=(A,W,b)\r\n",
        "\r\n",
        "  return Z,cache"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZBurqkB-t_Y"
      },
      "source": [
        "def forward_activation(W,A,b,activation):\r\n",
        "\r\n",
        "  if activation==\"sigmoid\":\r\n",
        "    Z,linear_cache=linear_forward(W,A,b)\r\n",
        "    A=sigmoid(Z)\r\n",
        "  \r\n",
        "  elif activation==\"relu\":\r\n",
        "    Z,linear_cache=linear_forward(W,A,b)\r\n",
        "    A=relu(Z)\r\n",
        "  \r\n",
        "  activation_cache=(linear_cache,Z)\r\n",
        "\r\n",
        "  return A,activation_cache"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLLCUjeMBtv1"
      },
      "source": [
        "def forward_propagation(X,parameters):\r\n",
        "\r\n",
        "  #A0 is X\r\n",
        "  A=X\r\n",
        "  L=len(parameters)//2\r\n",
        "  cache=[]\r\n",
        "\r\n",
        "  #looping through layers and applying the linear function and activation function\r\n",
        "  for l in range (1,L):\r\n",
        "    A,temp_cache=forward_activation(parameters[\"W\"+str(l)],A,parameters[\"b\"+str(l)],\"relu\")\r\n",
        "    cache.append(temp_cache)\r\n",
        "\r\n",
        "  AL,temp_cache=forward_activation(parameters[\"W\"+str(L)],A,parameters[\"b\"+str(L)],\"sigmoid\")\r\n",
        "  cache.append(temp_cache)\r\n",
        "\r\n",
        "  return AL,cache"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBlLLfhuXx8y"
      },
      "source": [
        "Calculating cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fXBrUNkX5go"
      },
      "source": [
        "def cost(AL,Y):\r\n",
        "  \r\n",
        "  m=Y.shape[1]\r\n",
        "\r\n",
        "  cost=-np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))/m\r\n",
        "\r\n",
        "  return np.squeeze(cost)"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqOYwviFBPdV"
      },
      "source": [
        "Backward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYH4nEwzBEvv"
      },
      "source": [
        "def linear_backward(dZ,cache):\r\n",
        "\r\n",
        "  A,W,b=cache\r\n",
        "  m=W.shape[1]\r\n",
        "\r\n",
        "  dW=np.dot(dZ,A.T)/m\r\n",
        "  db=np.sum(dZ,axis=1,keepdims=True)/m\r\n",
        "  dA=np.dot(W.T,dZ)\r\n",
        "\r\n",
        "  assert (dA.shape == A.shape)\r\n",
        "  assert (dW.shape == W.shape)\r\n",
        "  assert (db.shape == b.shape)\r\n",
        "\r\n",
        "  return dA,dW,db"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHwLi20wlLnn"
      },
      "source": [
        "def activation_backward(dA, cache, activation):\r\n",
        "    linear_cache, activation_cache = cache\r\n",
        "    \r\n",
        "    if activation == \"relu\":\r\n",
        "        dZ = derivative_relu(dA,activation_cache)\r\n",
        "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\r\n",
        "\r\n",
        "    elif activation == \"sigmoid\":\r\n",
        "        dZ = derivative_sigmoid(dA,activation_cache)\r\n",
        "        dA_prev, dW, db = linear_backward(dZ,linear_cache)\r\n",
        "    \r\n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZgFTNhAQO2r"
      },
      "source": [
        "def backward_propagation(AL,Y,cache):\r\n",
        "\r\n",
        "  gradient={}\r\n",
        "  L=len(cache)\r\n",
        "  Y=Y.reshape(AL.shape)\r\n",
        "\r\n",
        "  dAL=np.divide(AL-Y, (1 - AL) *  AL)\r\n",
        "\r\n",
        "  #finding the values of dAL-1,dWL and dbL\r\n",
        "  current_cache=cache[L-1]\r\n",
        "  gradient[\"dA\"+str(L-1)],gradient[\"dW\"+str(L)],gradient[\"db\"+str(L)]=activation_backward(dAL,current_cache,\"sigmoid\")\r\n",
        "\r\n",
        "  #looping through the layers 0 to L-2 to find the values of dA,dW and db for layers 1 to L-1\r\n",
        "  for l in reversed(range(L-1)):\r\n",
        "    current_cache=cache[l]\r\n",
        "    dA_temp,dW_temp,db_temp=activation_backward(gradient[\"dA\"+str(l+1)],current_cache,\"relu\")\r\n",
        "    gradient[\"dA\"+str(l)]=dA_temp\r\n",
        "    gradient[\"dW\"+str(l+1)]=dW_temp\r\n",
        "    gradient[\"db\"+str(l+1)]=db_temp\r\n",
        "  \r\n",
        "  return gradient"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyPR6c0xWA38"
      },
      "source": [
        "Updating parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBMTfo0NWAYF"
      },
      "source": [
        "def update_params(parameters,grads,learning_rate):\r\n",
        "\r\n",
        "  for l in range(1,len(parameters)//2+1):\r\n",
        "    parameters[\"W\"+str(l)]=parameters[\"W\"+str(l)]-learning_rate*grads[\"dW\"+str(l)]\r\n",
        "    parameters[\"b\"+str(l)]=parameters[\"b\"+str(l)]-learning_rate*grads[\"db\"+str(l)]\r\n",
        "  \r\n",
        "  return parameters"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfgSNIo7ZI5K"
      },
      "source": [
        "**Step 3:**Build the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqlzttWPZG3N"
      },
      "source": [
        "def neural_network(X, Y,layers, learning_rate, num_iterations):\r\n",
        "    costs = []                         \r\n",
        "    parameters = initialize_params(layers)\r\n",
        "\r\n",
        "    for i in range(0, num_iterations):\r\n",
        "        AL, cache = forward_propagation(X, parameters)\r\n",
        "        gradient = backward_propagation(AL, Y, cache)\r\n",
        "        parameters = update_params(parameters, gradient, learning_rate)\r\n",
        "        if i%100==0:\r\n",
        "          costs.append(cost(AL, Y))\r\n",
        "          print(AL)\r\n",
        "          \r\n",
        "    # plot the cost\r\n",
        "    plt.plot(np.squeeze(costs))\r\n",
        "    plt.ylabel('cost')\r\n",
        "    plt.xlabel('iterations (per hundreds)')\r\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "    return parameters"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6v3BQjAa20h"
      },
      "source": [
        "layers=[X_train.shape[0],700,200,50,10,1]\r\n",
        "parameters=neural_network(X_train,Y_train,layers,0.12,1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyrYcqWer6Ex"
      },
      "source": [
        "def prediction(X,parameters):\r\n",
        "  AL, cache = forward_propagation(X, parameters)\r\n",
        "  Y=[]\r\n",
        "\r\n",
        "  for i in range(AL.shape[1]):\r\n",
        "    if AL[0][i]<=0.5:\r\n",
        "      Y.append(0)\r\n",
        "    else:\r\n",
        "      Y.append(1)\r\n",
        "  return Y"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iXNZN8w84uf",
        "outputId": "a970578c-df79-48e7-a461-dfa2f0db6fe8"
      },
      "source": [
        "predicted_Y=prediction(X_train,parameters)\r\n",
        "print(predicted_Y)"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r_MQ2cMVipr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}